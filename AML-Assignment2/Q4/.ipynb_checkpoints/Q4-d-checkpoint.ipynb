{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question returns the testing and training error for various values of C and print the value of C that gives the least training and testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('features.train',header=None,delimiter=r\"\\s+\") #this takes dataframe from the training dataset\n",
    "df1 = pd.read_csv('features.test', header=None, delimiter=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.341092</td>\n",
       "      <td>-4.528937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.444131</td>\n",
       "      <td>-5.496812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.231002</td>\n",
       "      <td>-2.886750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>-3.534375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.291936</td>\n",
       "      <td>-4.352062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2\n",
       "0  6.0  0.341092 -4.528937\n",
       "1  5.0  0.444131 -5.496812\n",
       "2  4.0  0.231002 -2.886750\n",
       "3  7.0  0.200275 -3.534375\n",
       "4  3.0  0.291936 -4.352062"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the labels and features given the dataset(i.e it splits the last column for labels)\n",
    "def getDetails(dataset):\n",
    "    labels= dataset[:,0]\n",
    "    intensity= dataset[:,1]\n",
    "    symmetry= dataset[:,2]\n",
    "    features=np.column_stack((intensity,symmetry))\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 3)\n",
      "(1561, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset=df.values\n",
    "print(dataset.shape)\n",
    "dataset = dataset[np.logical_or(dataset[:,0]==1,dataset[:,0]==5)]\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2007, 3)\n",
      "(424, 3)\n"
     ]
    }
   ],
   "source": [
    "test_dataset= df1.values\n",
    "print(test_dataset.shape)\n",
    "test_dataset = test_dataset[np.logical_or(test_dataset[:,0]==1,test_dataset[:,0]==5)]\n",
    "print(test_dataset.shape)\n",
    "test_labels, test_features= getDetails(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for error rate  0.01 is for testing error is  2.358490566037736\n",
      "Error for error rate  0.01 is for training error is  0.3843689942344651\n",
      "\n",
      "Error for error rate  1 is for testing error is  2.1226415094339623\n",
      "Error for error rate  1 is for training error is  0.4484304932735426\n",
      "\n",
      "Error for error rate  100 is for testing error is  1.8867924528301887\n",
      "Error for error rate  100 is for training error is  0.3203074951953876\n",
      "\n",
      "Error for error rate  1000 is for testing error is  1.8867924528301887\n",
      "Error for error rate  1000 is for training error is  0.3203074951953876\n",
      "\n",
      "Error for error rate  1000000 is for testing error is  2.358490566037736\n",
      "Error for error rate  1000000 is for training error is  0.06406149903907751\n",
      "\n",
      "\n",
      "\n",
      "C for lowest testing error is  100\n",
      "C for lowest training error is  1000000\n"
     ]
    }
   ],
   "source": [
    "labels, features = getDetails(dataset)\n",
    "lowest_train_c=0\n",
    "lowest_training_error=100\n",
    "lowest_test_c=0\n",
    "lowest_testing_error=100\n",
    "for error_rate in [0.01, 1, 100, 1000, 1000000]:\n",
    "    clf = SVC(gamma=1,C=error_rate,kernel='rbf')\n",
    "    clf.fit(features, labels)\n",
    "    \n",
    "    test_set_lables=clf.predict(test_features)\n",
    "    correct_count=np.count_nonzero(test_set_lables != test_labels)\n",
    "    error= (correct_count*100)/((test_dataset.shape[0]))\n",
    "    print(\"Error for error rate \",error_rate,\"is for testing error is \",error)\n",
    "    if error< lowest_testing_error:\n",
    "        lowest_testing_error=error\n",
    "        lowest_test_c=error_rate\n",
    "        \n",
    "        \n",
    "    test_set_lables=clf.predict(features)# this helps in getting the training error by passing the training dataset through the predict\n",
    "    correct_count=np.count_nonzero(test_set_lables != labels)\n",
    "    error= (correct_count*100)/((dataset.shape[0]))\n",
    "    print(\"Error for error rate \",error_rate,\"is for training error is \",error)\n",
    "    print()\n",
    "    if error< lowest_training_error:\n",
    "        lowest_training_error=error\n",
    "        lowest_train_c=error_rate\n",
    "print()\n",
    "print()\n",
    "print(\"C for lowest testing error is \",lowest_test_c)\n",
    "print(\"C for lowest training error is \",lowest_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
