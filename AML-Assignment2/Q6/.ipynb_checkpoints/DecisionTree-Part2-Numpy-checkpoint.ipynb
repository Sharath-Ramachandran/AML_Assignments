{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS6510 HW 1 Code Skeleton\n",
    "# Please use this outline to implement your decision tree. You can add any code around this.\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "# Enter You Name Here\n",
    "myname = \"Doe-John-Sharath\" # or \"Doe-Jane-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropycal(class0count, class1count):\n",
    "    if(class0count>0 and class1count>0):\n",
    "        probclass0= float(class0count/(class0count+class1count))\n",
    "        probclass1=1-probclass0\n",
    "    else:\n",
    "        probclass0=0\n",
    "        probclass1=0\n",
    "        return 0\n",
    "    entropyCal= probclass0*(-1)*math.log(probclass0)+ probclass1*(-1)*math.log(probclass1)\n",
    "    return entropyCal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyFun(training_set, column_index, value):\n",
    "    classg=[row for row in training_set if float(row[column_index])>=value]\n",
    "    classl=[row for row in training_set if float(row[column_index])< value]\n",
    "    count_classg= len(classg)\n",
    "    count_classl=len(classl)\n",
    "    if(count_classg==0 and count_classl==0):\n",
    "        prob_classg=0\n",
    "        prob_classl=0\n",
    "    else:\n",
    "        prob_classg= float(count_classg/(count_classg+ count_classl))\n",
    "        prob_classl= 1-prob_classg\n",
    "    \n",
    "    classg0= [row for row in classg if float(row[-1])==0]\n",
    "    count_classg0=len(classg0)\n",
    "    classl0= [row for row in classl if float(row[-1])==0]\n",
    "    count_classl0=len(classl0)\n",
    "    count_classg1= len(classg)-count_classg0\n",
    "    count_classl1=len(classl)-count_classl0\n",
    "    \n",
    "    entropyg= entropycal(count_classg0, count_classg1)\n",
    "    entropyl= entropycal(count_classl0, count_classl1)\n",
    "    \n",
    "    entropyVal= prob_classg*entropyg+ prob_classl* entropyl\n",
    "    \n",
    "    return entropyVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSplit(training_set,entropy):\n",
    "    local_entropy=0\n",
    "    local_column=None\n",
    "    best_entropy=1\n",
    "    best_column=None\n",
    "    col_mean_final=0\n",
    "    '''if entropy==2:\n",
    "        entropy= calculateInitialEntropy(training_set)\n",
    "    '''\n",
    "    for col in range(0,len(training_set[0])-1):\n",
    "        \n",
    "        col_data= [float(row[col]) for row in training_set]\n",
    "        col_mean=float(np.sum(col_data)/len(col_data))\n",
    "        \n",
    "        local_entropy= entropyFun(training_set,col,col_mean)\n",
    "        #print(\"Local entropy for column \",col,\" is\", local_entropy,\" with value \",col_mean)\n",
    "        \n",
    "        if local_entropy< best_entropy:  \n",
    "            best_entropy=local_entropy\n",
    "            best_column = col\n",
    "            col_mean_final=col_mean\n",
    "\n",
    "    \n",
    "    return  best_entropy,best_column,col_mean_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(training_set, column_index, value):\n",
    "    true_rows= [row for row in training_set if float(row[column_index]) >= value]\n",
    "    false_rows = [row for row in training_set if float(row[column_index])< value]\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(training_set, column_index,value):\n",
    "    true_label= None\n",
    "    false_label=None\n",
    "    true_rows= [row for row in training_set if float(row[column_index]) >= value]\n",
    "    false_rows = [row for row in training_set if float(row[column_index])< value]\n",
    "    if len(true_rows)>0:\n",
    "        true_label = true_rows[0][-1]\n",
    "    if len(false_rows)>0:\n",
    "        false_label= false_rows[0][-1]\n",
    "    #print(type(false_label))\n",
    "    #print(type(true_label))\n",
    "    if false_label==\"1\":\n",
    "        false_label=\"class1\"\n",
    "    if true_label==\"0\":\n",
    "        true_label=\"class0\"\n",
    "    if false_label==\"0\":\n",
    "        false_label=\"class0\"\n",
    "    if true_label==\"1\":\n",
    "        true_label=\"class1\"\n",
    "    #print(\"For column \",column_index,\" with value\",value ,\"we have the true and false labels as\",true_label, false_label)\n",
    "    if len(true_rows)> len(false_rows):\n",
    "        return true_label\n",
    "    else:\n",
    "        return false_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    tree = {}\n",
    "\n",
    "    def learn(self, training_set,index, entropy):\n",
    "        #implement this function\n",
    "        value=0\n",
    "        true_index=0\n",
    "        false_index=0\n",
    "        entropy,column_name,value = findSplit(training_set,entropy)\n",
    "        #print(\"Entropy of column \",column_name,\" is \",entropy)\n",
    "        #check terminating criteria\n",
    "        if entropy==0:\n",
    "            #print(\"Base case for index \",index,\" column \",column_name)\n",
    "            return getClass(training_set, column_name, value)\n",
    "        # get the true and false rows based on the criteria\n",
    "        true_rows, false_rows = partition(training_set,column_name,value)\n",
    "        \n",
    "        \n",
    "        #print(\"True rows of col \",column_name, \"of index \",index)\n",
    "        #print(true_rows)\n",
    "        true_index= self.learn(true_rows, 2*index,entropy)\n",
    "            \n",
    "        #print(\"false rows of col \",column_name,\" of index \",index)\n",
    "        false_index= self.learn(false_rows,2*index+1, entropy)\n",
    "        \n",
    "        #print(\"True_Index for index \", index,true_index)\n",
    "        #print(\"False_Index for index \",index, false_index)\n",
    "        \n",
    "        self.tree[index]=[column_name,value,{\"true_rows\":true_index,\"false_rows\":false_index}]\n",
    "        return index\n",
    "    #implement this function\n",
    "\n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        result = 0 # baseline: always classifies as 0\n",
    "        #print(self.tree)\n",
    "        index=1\n",
    "        while 1:\n",
    "            value= self.tree[index]\n",
    "            column_num= value[0]\n",
    "            values=value[1]\n",
    "            if float(test_instance[column_num])>=float(values):\n",
    "                #print(value[2][\"true_rows\"])\n",
    "                result= value[2][\"true_rows\"]\n",
    "            else:\n",
    "                #print(value[2])\n",
    "                result=value[2][\"false_rows\"]\n",
    "            if result==\"class1\" or result==\"class0\":\n",
    "                break\n",
    "            else:\n",
    "                index=result\n",
    "        if result==\"class1\":\n",
    "            result=\"1\"\n",
    "        else:\n",
    "            result=\"0\"\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree():\n",
    "\n",
    "    # Load data set\n",
    "    with open(\"assign1-q1-data.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "    print(\"Number of records: %d\" % len(data))\n",
    "\n",
    "    # Split training/test sets\n",
    "    # You need to modify the following code for cross validation.\n",
    "    '''K = 10\n",
    "    training_set = [x for i, x in enumerate(data) if i % K != 9]\n",
    "    test_set = [x for i, x in enumerate(data) if i % K == 9]\n",
    "    print(\"test_set\",len(test_set))\n",
    "    print(\"training_set\",len(training_set))'''\n",
    "    sumOfaccuracy=0.0\n",
    "    for j in range(0,10):\n",
    "        K= 10\n",
    "        training_set = [x for i, x in enumerate(data) if i % K != j]\n",
    "        test_set = [x for i, x in enumerate(data) if i % K == j]\n",
    "        #print(test_set)\n",
    "        columns_set={}\n",
    "        tree = DecisionTree()\n",
    "        # Construct a tree using training set\n",
    "        tree.learn( training_set,1,2)\n",
    "        #print(tree)\n",
    "        # Classify the test set using the tree we just constructed\n",
    "        results = []\n",
    "        #print(test_set)\n",
    "        for instance in test_set:\n",
    "            result = tree.classify( instance[:-1] ) # prints all values except the last one\n",
    "            #print(\"Expected \",type(instance[-1]), type(result))\n",
    "            #print(\"Got::\",result== instance[-1])\n",
    "            results.append( result == instance[-1])\n",
    "        #tree.classify(training_set)\n",
    "        # Accuracy\n",
    "        accuracy = float(results.count(True))/float(len(results))\n",
    "        print(\"accuracy: %.4f\" % accuracy)       \n",
    "        sumOfaccuracy = sumOfaccuracy+accuracy\n",
    "    avg_accuracy= sumOfaccuracy/10\n",
    "    print(avg_accuracy)\n",
    "    # Writing results to a file (DO NOT CHANGE)\n",
    "    f = open(myname+\"result_10fold.txt\", \"w\")\n",
    "    f.write(\"accuracy: %.4f\" % avg_accuracy)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "accuracy: 0.8347\n",
      "accuracy: 0.8204\n",
      "accuracy: 0.8082\n",
      "accuracy: 0.8122\n",
      "accuracy: 0.8122\n",
      "accuracy: 0.7816\n",
      "accuracy: 0.8286\n",
      "accuracy: 0.8020\n",
      "accuracy: 0.8405\n",
      "accuracy: 0.7975\n",
      "0.8138036809815951\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
