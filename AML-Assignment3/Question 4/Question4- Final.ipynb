{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess( input_numpy):\n",
    "    print(\"Initial input shape \",input_numpy.shape)#check the initial shape the matrix\n",
    "    # remove the rows that have fares less than 0 (does not make sene)\n",
    "    input_numpy = input_numpy[input_numpy[:,1] >0]\n",
    "    # remove rows that have number of passengers less than 0 and greater than 6\n",
    "    input_numpy = input_numpy[input_numpy[:,-1]<7]\n",
    "    input_numpy = input_numpy[input_numpy[:,-1]>0]\n",
    "    #check the number of reduced it is reduced to\n",
    "    #convert the numpy to a dataframe and then remove rows that have missing data\n",
    "    input_df= pd.DataFrame(input_numpy)\n",
    "    # drop all the NAN rows\n",
    "    input_df = input_df.dropna(how = 'any', axis = 'rows')\n",
    "    #instead of having pickup and drop latitude and longitude, better to have the differnce between the latitude and longitude\n",
    "    input_df['diff_latitude']= (input_df[6] - input_df[4]).abs()\n",
    "    input_df['diff_longitude']= (input_df[5] - input_df[3]).abs()\n",
    "    input_df.drop([3,4,5,6],axis=1)\n",
    "    input_numpy= input_df.values\n",
    "    print(input_df.shape)\n",
    "    return input_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureSetandLabel(input_numpy):\n",
    "    input_labels= input_numpy[:,1]\n",
    "    input_features = input_numpy[:,2:]\n",
    "    return input_features, input_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "# this function returns 1 if it the day is a weekend or 0 if its a weekday\n",
    "def getDays(year, month, day):\n",
    "    list_days=[]\n",
    "    for  i in range(0,len(day)):\n",
    "        days=calendar.weekday(year[i],month[i],day[i])\n",
    "        if days>=5:\n",
    "            list_days.append(1)\n",
    "        else:\n",
    "            list_days.append(0)\n",
    "    return list_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returned 1 if the cab is being booked at night time(10pm-6am) and 0 if it is booked at day time\n",
    "def getNightShift(hour):\n",
    "    list_time=[]\n",
    "    for  i in range(0,len(hour)):\n",
    "        if(hour[i]>=0 and hour[i]<6) or(hour[i]==22 or hour[i]==23):\n",
    "            list_time.append(1)\n",
    "        else:\n",
    "            list_time.append(0)\n",
    "    return list_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the hour:minute:sec format and got only the hour\n",
    "def splitTimetoHMS(Time):\n",
    "    TimeFormat = [x.split(\":\") for x in Time]\n",
    "    TimeFormat = np.asarray(TimeFormat)\n",
    "    hour = TimeFormat[:,0]\n",
    "    hour= list(map(int,hour))\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the year,month and day as lists\n",
    "def splitDatetoYMD(dates):\n",
    "    dateFormat = [x.split(\"-\") for x in dates]\n",
    "    dateFormat = np.asarray(dateFormat)\n",
    "    year, month, day= dateFormat[:,0], dateFormat[:,1],dateFormat[:,2]\n",
    "    year= np.asarray(list(map(int,year)))\n",
    "    month= list(map(int,month))\n",
    "    day= list(map(int,day))\n",
    "    return year,month,day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDateTime(input_features):\n",
    "    dateTime= [x.split(' ') for x in input_features[:,0]]\n",
    "    dateTime = np.asarray(dateTime)\n",
    "    return dateTime[:,0], dateTime[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDateandTimeColumnsNumpy(input_features):\n",
    "    input_features[:,0]= [ x[:-3] for x in input_features[:,0]] # remove the UTC from the end of the column\n",
    "    dates, time= splitDateTime(input_features)\n",
    "    year,month,day= splitDatetoYMD(dates)\n",
    "    hour= splitTimetoHMS(time)\n",
    "    daysCount=getDays(year.tolist(),month,day)\n",
    "    daysCount=np.asarray(daysCount)\n",
    "    NightShiftCount=  getNightShift(hour)\n",
    "    secsCount = np.asarray(NightShiftCount)\n",
    "    return year,daysCount,secsCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinColumnsToNumpy(year,daysCount,secsCount,input_features):\n",
    "    input_features=np.hstack((input_features, year[:,None]))\n",
    "    input_features=np.hstack((input_features, daysCount[:,None]))\n",
    "    input_features=np.hstack((input_features, secsCount[:,None]))\n",
    "    return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             key  fare_amount          pickup_datetime  \\\n",
      "0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
      "1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
      "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
      "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
      "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
      "\n",
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
      "0        -73.844311        40.721319         -73.841610         40.712278   \n",
      "1        -74.016048        40.711303         -73.979268         40.782004   \n",
      "2        -73.982738        40.761270         -73.991242         40.750562   \n",
      "3        -73.987130        40.733143         -73.991567         40.758092   \n",
      "4        -73.968095        40.768008         -73.956655         40.783762   \n",
      "\n",
      "   passenger_count  \n",
      "0                1  \n",
      "1                1  \n",
      "2                2  \n",
      "3                1  \n",
      "4                1  \n",
      "Done loading the file\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "print(df.head())\n",
    "input_numpy= df.values\n",
    "print(\"Done loading the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial input shape  (1000, 8)\n",
      "(997, 10)\n",
      "After preprocessing the input size is  (997, 10)\n"
     ]
    }
   ],
   "source": [
    "input_numpy= preProcess(input_numpy)\n",
    "print(\"After preprocessing the input size is \",input_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with splitting features and labels\n"
     ]
    }
   ],
   "source": [
    "input_features, input_labels= getFeatureSetandLabel(input_numpy)\n",
    "print(\"Done with splitting features and labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained the columns to be added to the numpy\n"
     ]
    }
   ],
   "source": [
    "input_year,input_daysCount,input_secsCount= getDateandTimeColumnsNumpy(input_features)\n",
    "print(\"Obtained the columns to be added to the numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added the columns to the numpy\n"
     ]
    }
   ],
   "source": [
    "input_features = joinColumnsToNumpy(input_year,input_daysCount,input_secsCount,input_features)\n",
    "print(\"Added the columns to the numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the first feature\n"
     ]
    }
   ],
   "source": [
    "input_features=np.delete(input_features,0, 1)\n",
    "print(\"Removed the first feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape  (997, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape \",input_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can uncomment any model that is needed\n",
    "# from sklearn.svm import SVR\n",
    "# clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "clf = GradientBoostingRegressor()\n",
    "# from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "# clf= HuberRegressor()\n",
    "# clf = AdaBoostRegressor()\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# clf=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(input_features,input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           key          pickup_datetime  pickup_longitude  \\\n",
      "0  2015-01-27 13:08:24.0000002  2015-01-27 13:08:24 UTC        -73.973320   \n",
      "1  2015-01-27 13:08:24.0000003  2015-01-27 13:08:24 UTC        -73.986862   \n",
      "2  2011-10-08 11:53:44.0000002  2011-10-08 11:53:44 UTC        -73.982524   \n",
      "3  2012-12-01 21:12:12.0000002  2012-12-01 21:12:12 UTC        -73.981160   \n",
      "4  2012-12-01 21:12:12.0000003  2012-12-01 21:12:12 UTC        -73.966046   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0        40.763805         -73.981430         40.743835                1  \n",
      "1        40.719383         -73.998886         40.739201                1  \n",
      "2        40.751260         -73.979654         40.746139                1  \n",
      "3        40.767807         -73.990448         40.751635                1  \n",
      "4        40.789775         -73.988565         40.744427                1  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "print(test_df.head())\n",
    "test_df['diff_latitude']= (test_df.dropoff_latitude - test_df.pickup_latitude).abs()\n",
    "test_df['diff_longitude']= (test_df.dropoff_longitude - test_df.pickup_longitude).abs()\n",
    "test_df.drop(['dropoff_latitude','dropoff_longitude','pickup_latitude','pickup_latitude'],axis=1)\n",
    "test_numpy=  test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy= test_numpy[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "year,daysCount,secsCount = getDateandTimeColumnsNumpy(test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy=joinColumnsToNumpy(year,daysCount,secsCount,test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy=np.delete(test_numpy,0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels= clf.predict(test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# saved the result as submission.csv\n",
    "test_df[\"fare_amount\"]=test_labels\n",
    "test_df[[\"key\",\"fare_amount\"]].to_csv(\"submission.csv\",index=False)\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
